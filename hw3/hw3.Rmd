---
title: "hw3"
author: "Xingwen Wei, Xin Hu, Liding Li"
date: "March 6, 2021"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Question 1

The true model is a polynomial of degree 3.

```{r}
m <- matrix(c('high', 'low', 'low', 'low', 'low', 'high'), ncol=2, byrow=FALSE)
colnames(m) <- c('Bias', 'Variance')
rownames(m) <- c('Linear regression', 'Polynomial regression with degree 3', 
                 'Polynomial regression with degree 10')
as.table(m)
```

## Question 2

### a

As $\lambda \rightarrow \infty$, $\hat{g_1}$ will have all $g^{(3)}(x)=0$ and $\hat{g_2}$ will have all $g^{(4)}(x)=0$.
So this is similar to constraining $\hat{g_1}$ to have degree less than 3 and $\hat{g_2}$ less than 4.
Thus, $\hat{g_2}$ will always have smaller or equal training error than $\hat{g_1}$.

### b

On one hand, if the true curve has degree higher than or equal to 3, $\hat{g_1}$ will not be able to capture it at all, while $\hat{g_2}$ can capture it. So $\hat{g_2}$ will have the smaller test error in this case.
On the other hand, if the true curve has degree smaller than 3, $\hat{g_2}$ may pick some noise up as signal and overfits the training data, while $\hat{g_1}$ will not. So $\hat{g_1}$ will have the smaller test error in this case.


### c

For $\lambda = 0$, $\hat{g_1} = \hat{g_2}$. So they will have the same training and test error.

## Question 3

### a

Exploratory Data Analysis
```{r, echo=F, warning=F}
library(ggplot2)
library(tidyr)
library(GGally)
ozone <- read.table("C:/Users/xingw/Desktop/503/stats503/hw3/ozone_data.txt", header=1)
summary(ozone)
ozone_long <- gather(ozone, predictor, value, 2:4, factor_key = TRUE)
ggplot(ozone_long, aes(y=value)) + geom_boxplot(fill='slateblue', alpha=0.2) + facet_wrap(vars(predictor), scales = 'free_y')
```

According to the model summary, the linear model we choose is
$$
\text{ozone}^{\frac{1}{3}}=0.001\times \text{radiation} + 0.056\times \text{temperature}-0.072\times\text{wind}-0.654
$$

```{r}
set.seed(2021)
ozone <- read.table("C:/Users/xingw/Desktop/503/stats503/hw3/ozone_data.txt", header=1)
train <- sample(nrow(ozone), floor(nrow(ozone)*0.7))
ozone$cbr <- ozone$ozone^(1/3)
lmod <- lm(cbr~radiation+temperature+wind, data=ozone[train, ])
summary(lmod)
```

### b

We use LOOCV to find to optimal number of knots.
According to the LOOCV, we find that we get the best result when $\lambda=3$.
Based on the fitted splines plot of each variables, we find that temperature looks linear where radiation and wind does not.

```{r, warning=F}
library(gam)
train_loo <- ozone[train, ]
errors <- matrix(NA, nrow=nrow(train_loo), ncol=10)
ss <- 1:10
for(i in 1:nrow(train_loo)){
  train1 <- train_loo[-i, ]
  test1 <- train_loo[i, ]
  for(k in 1:10){
    gam_mod <- gam(cbr~s(radiation, ss[k])+s(temperature, ss[k])+s(wind, ss[k]), data=train1)
    pred <- predict(gam_mod, test1)
    errors[i, k] <- (test1$cbr-pred)^2
  }
}
gam_mod <- gam(cbr~s(radiation, 3)+s(temperature, 3)+s(wind, 3), data=ozone[train, ])
par(mfrow=c(1, 3))
plot.Gam(gam_mod)
```

### c

The mean test error for linear model is 0.316.
On the other hand, we get a test error of 0.232 with GAM.
According to both residual plots, the error terms are roughly normally distributed around 0 with no apparent pattern.
We believe the nonlinearity is better captured by GAM and resulted in a better test error than the linear model.
We suspect that the non-linearity we observed in fitted spline plots above may be a result of small sample size.

```{r}
par(mfrow=c(1, 2))
pred <- predict(lmod, ozone[-train, ])
lm_mse <- sum((pred-ozone[-train, 'cbr'])^2)/nrow(ozone[-train, ])
plot(pred-ozone[-train, 'cbr'], ylab='residual', main='linear model residual plot')

gam_pred <- predict(gam_mod, ozone[-train, ])
gam_mse <- sum((gam_pred-ozone[-train, 'cbr'])^2)/nrow(ozone[-train, ])
plot(gam_pred-ozone[-train, 'cbr'], ylab='residual', main='GAM residual plot')

```


### d

According to the pairwise scatterplot, we find there is a rather strong linear relationship between temperature and wind and the cubic root of ozone, as corroberated by the correlation coefficients 0.75 and -0.6 respectively.
One can argue that the radiation does not have a strong linear relationship with the response variable, with correlation coefficient of 0.42.
However, it is clear that lower values of radiations are associated with lower values of cubic root of ozone and higher values of radiations are associated with higher values of cubic root of ozone.
Another perspective is provided by the GAM summary where there is significant statistical evidence to show the nonlinearity in temperature and wind, while not for radiation.
We believe this inconsistency is a result of the small sample size.
Therefore, we would not apply GAM in this dataset with about 100 observations without further strong evidence for nonlinearity.

```{r, out.height='80%', out.width='80%'}
ggpairs(ozone)
plot(ozone$radiation, ozone$cbr, xlab='radiation', ylab=expression(ozone^(1/3)))
ts <- lm(ozone$cbr~ozone$radiation)
pred1 <- predict(ts, ozone['radiation'])
lines(x=ozone$radiation, y=pred1, col='red')
summary(gam_mod)
```







